*** 2 techniques pour faire du cloisonnement entre des environnements

> Approche des VM

    -les VM virtualisent le matériel et un OS
    -permet une isolation complète des appli, car une VM contient une appli, ses dépendances et un OS
    -un hyperviseur permet de gérer et d'exécuter les VM
    -très couteux en espace et en CPU
    -duplication des fonctionnalités systèmes
    -démarre en qq dizaines de secondes
    => ce qui consomme beaucoup de ressources (CPU, mémoire)


> Docker

    = outil permettant d'exécuter des applications et leurs dépendances dans des conteneurs sur n'importe quel serveur (= conteneurisation)
    -tourne sur la machine hôte Linux
    -pas besoin d'un hyperviseur donc plus léger
    -représente une couche abstraite
    -utilisation des fonctionnalités de l'OS hôte, donc pas de la virtualisation
    -cloisonnement des applications
    -tests unitaires plus rapides à lancer que en VM => gain de temps
    -les conteneurs contiennent tous les paramétrages, livrables et ressources et démarrent en qq centaines de millisecondes


*** Présentation

-logiciel client serveur utilisant des fonctionnalités bas niveau du noyau linux
-Docker hub : registre publique
-Docker registry : stocke des images docker
-2 éditions : Community Edition et Enterprise Edition
-microservices plutôt que app monolithique
-un conteneur peut être exécutée sur n'importe quelle machine disposant de docker
-alternatives à Docker
    rkt
    kata container
-docker engine = moteur docker
-on peut préciser l'utilisation des LXC


*** Avantages

-lancer une app facilement et rapidement pour la tester, adapté aux déploiements récurrents
-consommation faibles de ressources
-portabilité d'exécution des appli sur une grande variété d'environnement dont le cloud
-créer de multiple environnement : tests, dev, proche de la prod
-scalabilité
-garder propre l’OS sous jacent
-limite la contagion virale
-adapté à DevOps
-sandbox pour navigateur


*** Inconvénients

-environnement 64 bits uniquement
-applications legacy doivent être adaptées aux conteneurs


*** Docker engine

= docker client + docker host
-docker client = client de Docker host qui intéragit avec le daemon via l’API
-docker host = machine virtuelle où les conteneurs sont déployés
    -daemon docker : moteur d'exécution des conteneurs qui gère des objets Docker (images, conteneurs, volumes et réseau), et écoute l'API. Récupère les images d'un docker registry
    -API : interface pour communiquer avec le daemon
    -images
    -conteneurs


*** Conteneur

-empaquete le code, la config et les dépendances de l'appli (bibliothèques et environnement d'exécution)
    => cela permet d'exécuter les appli sur une grande variété de systèmes hôtes
-par défaut, les conteneurs sont isolés de leur environnement (les autres appli et la machine), ce qui évitent les conflits
-une image en cours d'exécution
-a un cycle de vie avec un état
-contraintes sur l'utilisation des ressources
-principe : un conteneur = un processus / une application
-chaque conteneur fait partie d'un réseau et à sa propre adresse IP
-pas un objet mais une abstraction de plusieurs fonctionnalités linux
-étapes docker run :
    -docker pull <image_name>
    -docker create
    -allocation filesystem pour le conteneur
    -création d'une interface pour connecter le conteneur à un réseau
    -docker start


*** Image docker

= snapshot d’un conteneur
-package incluant tout ce qu'il faut pour lancer un conteneur :
    -code
    -variables d'environnement
    -bibliothèques
    -fichiers de config
-créée à partir d'un fichier dockerfile, qui contient toutes les instructions pour créer l'image
-une image est une superposition de couche, contenant les différentes applications. Cela permet de restaurer une version précédente
-l'exécution d'une image donne un conteneur
-docker registry = système de stockage d'images
-image en lecture seule
-Docker définit par défaut le point d’entrée sur /bin/sh -c
-une image peut avoir un tag : latest …


*** Volumes

-par défaut, les données modifiées d'un conteneur ne persistent pas après relance
    -> à l'exécution, les layers de l'image sont en lecture seule
    -> une couche en lecture-écriture est ajoutée et contient les modifications
    -> cette ensemble de couche est appelé 'Union File System'
-volumes = fichiers, sur l'hôte, utilisés pour la persistance des données
-chemin hôte : /var/lib/docker/volumes/<nom_v>
-utiliser -v dans docker run pour monter un volume


bridge
    = par défaut, les conteneurs sont invisibles de l’extérieur et ne voient pas les autres conteneurs, -p pour être visible
    pas de résolution DNS, to communication par IP
    réseau par défaut si aucun driver spécifié
    le daemon établit une couche d’indirection, appelée docker0, entre l’interface réseau de l'hôte et celle des containers
    les paquets peuvent passer des containers au réseau de l'hôte
    les conteneurs ont une adresse IP sur docker0

none
    pas de réseau, donc étanche
    en cas d’utilisation d’un réseau personnalisé

host
    le conteneur est visible de l’extérieur, donc pas d’isolation

overlay
    multihost

MACVLAN
    mise en commun de la couche réseau
    docker assigne une adresse MAC à chaque conteneur


à l’installation, 3 réseaux sont créés : bridge, host, none


-monter un volume

les conteneurs sont en lecture seule, les modifs sont ajoutées dans une couche supplémentaire. On peut utiliser commit pour créer une nouvelle image contenant ces modif
volume : modification dans un répertoire situé sur le disque dur de l'hôte
partager un volume entre plusieurs conteneurs
pose des problèmes de sécurité, créer des utilisateurs dans les conteneurs

manage app data : 
    bind mount : dependent on the directory structure and OS of the host machine
    volume : completely managed by Docker
    tmpfs mount : no persistence if container stop


*** réseau

-permettre aux conteneurs de communiquer entre eux et avec le monde extérieur
-types de réseaux ou driver :
    -bridge : 
        -réseau créé à l'installation de Docker et connecté à l'interface docker0
        -les conteneurs l'utilisent par défaut
        -conteneurs non accessibles depuis l'extérieur par défaut (configurer le mappage de port pour l'être)
    -none : le conteneur n'a pas d'interface et ne peut pas communiquer
    -host : pas d'isolation réseau, donc les conteneurs utilisent la même interface que l'hôte et sont accessibles depuis l'extérieur
    -overlay : créer un réseau distribué entre plusieurs hôtes Docker
    -macvlan : connecter une app au réseau physique, par attribution d'une adresse MAC à un conteneur

-3 réseaux créés automatiquement
    -bridge, type bridge, interface docker0, réseau par défaut
    -host, type host
    -none, type null
-on peut créer des "réseaux définis par l'utiliteur" ou "user defined networks"
    -permet la résolution DNS des noms d'hôtes


*** registry Docker

= système de stockage d'images Docker
-Docker Hub = registry public contenant de nombreuses images
-on peut en créer des privés


*** installation

docker.io : debian
    sudo apt-get install -y docker.io

docker-ce : par docker inc


*** Manage Docker as a non-root user

sudo groupadd docker
sudo usermod -aG docker $USER
newgrp docker


-------------------------------------------------------------------------------------


Here are 12 things I wish I learned a lot earlier about Docker and containers in general:
    Containers are about portability and resource utilization.
    Containers were not designed as a security containment mechanism from the start, and it shows.
    Containers don’t exist as a first-class object - Linux namespaces and cgroups work together to create “containers”.
    Multiple processes can run in the same “container”, this only means the processes share the same namespaces and cgroup.
    Docker is just one tool of many which you can use to work with containers.
    Docker works three main jobs: packaging apps into images, distributing images and running containers from images.
    Image layers exist to reuse work, transfer less data and save bandwidth.
    Docker is easy to get started with, but the images are too permissive and not correct by default.
    Lots of people use containers badly, and don’t even know it.
    It’s okay to use docker-compose for production workloads running on a single machine.
    Container orchestration, security and building good images take effort and experience. They are complex topics by themselves.
    Sometimes it’s okay to not-use Docker even though you could.
