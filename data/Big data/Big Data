= désigne les ressources d’informations dont les caractéristiques en termes de volume, de vélocité et de variété imposent l’utilisation de technologies et de méthodes analytiques particulières pour générer de la valeur
-Data lake = dépôt de données brutes accessible en lecture seule
-datanode = un serveur d'un réseau
-namenode = serveur central. route et administre les nodes, distribue les chunks, ne fait pas de traitements. Il est rack-aware
-redondance des chunks
-secondary namenode = prend le relais si le namenode tombe en panne
-élasticité = capacité d'un système à s'adapter en fonction du nombre de serveurs et de la quantité de données à répartir
hadoop 
    = stockage et traitement de large volume de données
    HDFS et MapReduce
spark
base de données distribuées
données structurées / non structurées
Google File System
CEPH
RDD
NoSQL
Cassandra
HBase
Graphe
Teradata
SQL
R
Apache Spark
Yet Another Resource Negotiator (YARN)
Data Warehouses
Data lake
cluster computing
moteur de requête Presto
Kafka
HPDA (High Performance Data Analytics)
ACID / BASE
business intelligence = analyse des données et de présentation d'informations pour aider les dirigeants, managers et autres utilisateurs finaux de l'entreprise à prendre des décisions business éclairées
data mining = analyse des données brutes pour en tirer des tendances
Data engineer
Data analyst
Data mining
HPDA (High Performance Data Analytics)
Hadoop Distributed File System (HDFS)
Map reduce
Data Warehouses
Data lake
cluster computing
moteur de requête Presto
kafka
data vizualisation : matplotlib, seaborn, cartopy, bokeh

_____________________________________________________________________

big data = représente les collections de données caractérisées par un volume, une vélocité et une variété si grands que leur transformation en valeur utilisable requiert l’utilisation de technologies et de méthodes analytiques spécifiques

Volume = pas d'échantillonnage, on observe et mesure tout 
Vélocité = les données et les résultats sont souvent disponibles en temps réel 
Variété = puise dans les données textuelles, les photos, audio / vidéo et complète généralement les pièces manquantes en fusionnant plusieurs sources

=> nouvelles techniques d’analyse (mapreduce, hadoop, google file system)

Applications
    génomique
    algo de recommandation (Netflix, …)
    détection de fraude
    sciences
    santé


compétences
    Affiner la qualité des données
    en réduire le volume
    développer des méthodes de navigation, d’analyse et de visualisation des grandes quantités de données, et des méthodes d’évaluation pour mesurer l’efficacité et l’utilisabilité de ces visualisations


*** sharding
-distribuer des chunks (bout de fichiers) sur un ensemble de serveurs
-3 familles
    -HDFS : distribution
    -clustered index : BTree
    -consistent hashing : tables de hachage


*** HDFS (Hadoop Distributed File System)
= technique de distribution de fichiers volumineux
